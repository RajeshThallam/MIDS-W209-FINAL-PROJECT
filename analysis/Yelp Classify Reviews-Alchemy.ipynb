{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting settings.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile settings.py\n",
    "class Settings:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    REVIEWS_FILE = '/home/rt/wrk/w209/yelp/data/reviews.json'\n",
    "    MONGO_CONNECTION_STRING = \"mongodb://localhost:27017/\"\n",
    "    REVIEWS_DATABASE = \"yelp\"\n",
    "    TAGS_DATABASE = \"tags\"\n",
    "    REVIEWS_COLLECTION = \"reviews\"\n",
    "    CORPUS_COLLECTION = \"corpus\"\n",
    "    DATA = '/home/rt/wrk/w209/yelp/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentimental Analysis of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mongodb://localhost:27017/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from settings import Settings\n",
    "Settings.MONGO_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 out of 4137 in 6.44797301292\n",
      "Done 200 out of 4137 in 14.6261591911\n",
      "Done 300 out of 4137 in 22.4360771179\n",
      "Done 400 out of 4137 in 30.5278820992\n",
      "Done 500 out of 4137 in 38.2301311493\n",
      "Done 600 out of 4137 in 46.2462801933\n",
      "Done 700 out of 4137 in 53.5938122272\n",
      "Done 800 out of 4137 in 59.9264461994\n",
      "Done 900 out of 4137 in 66.6041970253\n",
      "Done 1000 out of 4137 in 73.3279311657\n",
      "Done 1100 out of 4137 in 79.9920830727\n",
      "Done 1200 out of 4137 in 86.4331321716\n",
      "Done 1300 out of 4137 in 92.8286862373\n",
      "Done 1400 out of 4137 in 99.6583511829\n",
      "Done 1500 out of 4137 in 106.010366201\n",
      "Done 1600 out of 4137 in 111.845634222\n",
      "Done 1700 out of 4137 in 118.660789013\n",
      "Done 1800 out of 4137 in 124.495611191\n",
      "Done 1900 out of 4137 in 130.535201073\n",
      "Done 2000 out of 4137 in 136.727561235\n",
      "Done 2100 out of 4137 in 143.076666117\n",
      "Done 2200 out of 4137 in 149.159456015\n",
      "Done 2300 out of 4137 in 154.988416195\n",
      "Done 2400 out of 4137 in 160.120029211\n",
      "Done 2500 out of 4137 in 164.8184762\n",
      "Done 2600 out of 4137 in 170.186202049\n",
      "Done 2700 out of 4137 in 174.753567219\n",
      "Done 2800 out of 4137 in 179.298853159\n",
      "Done 2900 out of 4137 in 184.032380104\n",
      "Done 3000 out of 4137 in 188.906502008\n",
      "Done 3100 out of 4137 in 193.502275229\n",
      "Done 3200 out of 4137 in 198.159779072\n",
      "Done 3300 out of 4137 in 202.833622217\n",
      "Done 3400 out of 4137 in 207.535143137\n",
      "Done 3500 out of 4137 in 213.02383709\n",
      "Done 3600 out of 4137 in 217.313434124\n",
      "Done 3700 out of 4137 in 221.606396198\n",
      "Done 3800 out of 4137 in 225.669957161\n",
      "Done 3900 out of 4137 in 230.527662039\n",
      "Done 4000 out of 4137 in 236.129035234\n",
      "Done 4100 out of 4137 in 242.684406042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:44: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "\n",
    "from settings import Settings\n",
    "\n",
    "\n",
    "reviews_collection = MongoClient(Settings.MONGO_CONNECTION_STRING)[Settings.REVIEWS_DATABASE][Settings.REVIEWS_COLLECTION]\n",
    "tags_collection = MongoClient(Settings.MONGO_CONNECTION_STRING)[Settings.TAGS_DATABASE][Settings.REVIEWS_COLLECTION]\n",
    "\n",
    "reviews_cursor = reviews_collection.find({'business_id': '4bEjOyTaDG24SY5TxsaUNQ'})\n",
    "reviews_count = reviews_cursor.count()\n",
    "reviews_cursor.batch_size(1000)\n",
    "\n",
    "stopwords = {}\n",
    "with open('stopwords.txt', 'rU') as f:\n",
    "    for line in f:\n",
    "        stopwords[line.strip()] = 1\n",
    "\n",
    "done = 0\n",
    "start = time.time()\n",
    "\n",
    "for review in reviews_cursor:\n",
    "    words = []\n",
    "    sentences = nltk.sent_tokenize(review[\"text\"].lower().replace('\\r\\n', ' '))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        text = [word for word in tokens if word not in stopwords]\n",
    "        tagged_text = nltk.pos_tag(text)\n",
    "\n",
    "        for word, tag in tagged_text:\n",
    "            words.append({\"word\": word, \"pos\": tag})\n",
    "        \n",
    "        #print sentence\n",
    "\n",
    "    tags_collection.insert_many({\n",
    "        \"reviewId\": review[\"review_id\"],\n",
    "        \"business\": review[\"business_id\"],\n",
    "        \"text\": review[\"text\"],\n",
    "        \"stars\": review[\"stars\"],\n",
    "        \"words\": words\n",
    "    })\n",
    "\n",
    "    done += 1\n",
    "    if done % 100 == 0:\n",
    "        end = time.time()\n",
    "        os.system('cls')\n",
    "        print 'Done ' + str(done) + ' out of ' + str(reviews_count) + ' in ' + str((end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rt/wrk/w209/yelp/data\n"
     ]
    }
   ],
   "source": [
    "print Settings.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "with open(os.path.join(Settings.DATA, 'positive.csv'),'r') as infile:\n",
    "    pos_reviews = infile.readlines()\n",
    "\n",
    "with open(os.path.join(Settings.DATA, 'negative.csv'),'r') as infile:\n",
    "    neg_reviews = infile.readlines()\n",
    "\n",
    "with open(os.path.join(Settings.DATA, 'unsup.csv'),'r') as infile:\n",
    "    unsup_reviews = infile.readlines()\n",
    "\n",
    "#use 1 for positive sentiment, 0 for negative\n",
    "y = np.concatenate((np.ones(len(pos_reviews)), np.zeros(len(neg_reviews))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos_reviews, neg_reviews)), y, test_size=0.2)\n",
    "\n",
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "unsup_reviews = cleanText(unsup_reviews)\n",
    "\n",
    "#Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "#We do this by using the LabeledSentence method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "#a dummy index of the review.\n",
    "def labelizeReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeReviews(x_train, 'TRAIN')\n",
    "x_test = labelizeReviews(x_test, 'TEST')\n",
    "unsup_reviews = labelizeReviews(unsup_reviews, 'UNSUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize_docs(text):\n",
    "    return numpy.random.permutation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(unsup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(randomize_docs(unsup_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_shared/Google Drive/UCB - MIDS/1 - COURSE/W209 - Data Visualization/workspace/final_project/build\r\n"
     ]
    }
   ],
   "source": [
    "!cd /home/rt/wrk/w209/yelp/data\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/rt/wrk/w209/yelp/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18507"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'pos.txt'), 'r') as infile:\n",
    "    pos_reviews = infile.readlines()\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'neg.txt'), 'r') as infile:\n",
    "    neg_reviews = infile.readlines()\n",
    "\n",
    "# use 1 for positive sentiment, 0 for negative\n",
    "y = np.concatenate((np.ones(len(pos_reviews)), np.zeros(len(neg_reviews))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos_reviews, neg_reviews)), y, test_size=0.2)\n",
    "\n",
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    corpus = [z.lower().replace('\\n','').split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "\n",
    "n_dim = 300\n",
    "#Initialize model and build vocab\n",
    "review_w2v = Word2Vec(size=n_dim, min_count=10)\n",
    "review_w2v.build_vocab(x_train)\n",
    "\n",
    "#Train the model over train_reviews (this may take several minutes)\n",
    "review_w2v.train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build word vector for training set by using the average value of all word vectors in the reviews, then scale\n",
    "def buildWordVector(text, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += review_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:supplied example count (50) did not equal expected count (200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4237"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "train_vecs = np.concatenate([buildWordVector(z, n_dim) for z in x_train])\n",
    "train_vecs = scale(train_vecs)\n",
    "\n",
    "#Train word2vec on test reviews\n",
    "review_w2v.train(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build test tweet vectors then scale\n",
    "test_vecs = np.concatenate([buildWordVector(z, n_dim) for z in x_test])\n",
    "test_vecs = scale(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "lr.fit(train_vecs, y_train)\n",
    "\n",
    "print 'Test Accuracy: %.2f'%lr.score(test_vecs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr.predict(test_vecs)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAxSchcRiUFK7iIiMej/A675WdnzDvvdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0385f07310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#Create ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_probas = lr.predict_proba(test_vecs)[:,1]\n",
    "\n",
    "fpr,tpr,_ = roc_curve(y_test, pred_probas)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.plot(fpr,tpr,label='area = %.2f' %roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = '/home/rt/wrk/w209/yelp/data'\n",
    "with open(os.path.join(DATA_DIR, 'pos.txt'), 'r') as infile:\n",
    "    pos_reviews = infile.readlines()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'pos.txt'), 'r') as infile:\n",
    "    pos_reviews = infile.readlines()[:10]\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'neg.txt'), 'r') as infile:\n",
    "    neg_reviews = infile.readlines()[:10]\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'unsup.txt'), 'r') as infile:\n",
    "    unsup_reviews = infile.readlines()[:10]\n",
    "\n",
    "#use 1 for positive sentiment, 0 for negative\n",
    "y = np.concatenate((np.ones(len(pos_reviews)), np.zeros(len(neg_reviews))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos_reviews, neg_reviews)), y, test_size=0.2)\n",
    "\n",
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    punctuation = '\".,?!:;(){}[]'\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "unsup_reviews = cleanText(unsup_reviews)\n",
    "\n",
    "#Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "#We do this by using the LabeledSentence method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "#a dummy index of the review.\n",
    "def labelizeReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeReviews(x_train, 'TRAIN')\n",
    "x_test = labelizeReviews(x_test, 'TEST')\n",
    "unsup_reviews = labelizeReviews(unsup_reviews, 'UNSUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "size = 400\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, workers=16)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, dm=0, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build vocab over all reviews\n",
    "all_words = x_train + x_test + unsup_reviews\n",
    "model_dm.build_vocab(x_train)\n",
    "model_dbow.build_vocab(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_reviews = np.concatenate((x_train, unsup_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We pass through the data set multiple times, shuffling the training reviews each time to improve accuracy.\n",
    "for epoch in range(1):\n",
    "    print epoch\n",
    "    perm = np.random.permutation(all_train_reviews.shape[0])\n",
    "    print perm\n",
    "    model_dm.train(all_train_reviews[perm])\n",
    "    #model_dbow.train(all_train_reviews[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training set vectors from our models\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model[z.labels[0]]).reshape((1, size)) for z in corpus]\n",
    "    return np.concatenate(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))\n",
    "\n",
    "#train over test set\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    print \"iteration: {}\".format(epoch)\n",
    "    perm = np.random.permutation(x_test.shape[0])\n",
    "    model_dm.train(x_test[perm])\n",
    "    model_dbow.train(x_test[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct vectors for test reviews\n",
    "test_vecs_dm = getVecs(model_dm, x_test, size)\n",
    "test_vecs_dbow = getVecs(model_dbow, x_test, size)\n",
    "\n",
    "test_vecs = np.hstack((test_vecs_dm, test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "size = 400\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, workers=3)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, dm=0, workers=3)\n",
    "\n",
    "#build vocab over all reviews\n",
    "all_words = x_train + x_test + unsup_reviews\n",
    "model_dm.build_vocab(x_train)\n",
    "model_dbow.build_vocab(x_train)\n",
    "\n",
    "#We pass through the data set multiple times, shuffling the training reviews each time to improve accuracy.\n",
    "all_train_reviews = np.concatenate((x_train, unsup_reviews))\n",
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(all_train_reviews.shape[0])\n",
    "    model_dm.train(all_train_reviews[perm])\n",
    "    model_dbow.train(all_train_reviews[perm])\n",
    "\n",
    "#Get training set vectors from our models\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model[z.labels[0]]).reshape((1, size)) for z in corpus]\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))\n",
    "\n",
    "#train over test set\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print \"iteration: {}\".format(epoch)\n",
    "    perm = np.random.permutation(x_test.shape[0])\n",
    "    model_dm.train(x_test[perm])\n",
    "    model_dbow.train(x_test[perm])\n",
    "\n",
    "#Construct vectors for test reviews\n",
    "test_vecs_dm = getVecs(model_dm, x_test, size)\n",
    "test_vecs_dbow = getVecs(model_dbow, x_test, size)\n",
    "\n",
    "test_vecs = np.hstack((test_vecs_dm, test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.doc2vec.FAST_VERSION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
